{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0ce6c6",
   "metadata": {},
   "source": [
    "## Report2\n",
    "\n",
    "**Date:** 2024-05-18  \n",
    "**Author:** Piotr Szepietowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c205fd01",
   "metadata": {},
   "source": [
    "## External Python Libraries Used\n",
    "\n",
    "    - Numpy\n",
    "    - matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaaa1f5",
   "metadata": {},
   "source": [
    "## Jacobi Iterative Method\n",
    "\n",
    "The Jacobi method is an iterative method for solving systems of linear equations. It consists of the following steps:\n",
    "\n",
    "1. **Initial condition:** The system of equations must be written in matrix form Ax = b, where:\n",
    "    - A is the coefficient matrix\n",
    "    - x is the vector of unknowns\n",
    "    - b is the vector of constants\n",
    "\n",
    "2. **System transformation:** For each equation, express the unknown xi through the remaining variables:\n",
    "    ```\n",
    "    x₁ = (b₁ - a₁₂x₂ - a₁₃x₃ - ... - a₁ₙxₙ) / a₁₁\n",
    "    x₂ = (b₂ - a₂₁x₁ - a₂₃x₃ - ... - a₂ₙxₙ) / a₂₂\n",
    "    ...\n",
    "    xₙ = (bₙ - aₙ₁x₁ - aₙ₂x₂ - ... - aₙ,ₙ₋₁xₙ₋₁) / aₙₙ\n",
    "    ```\n",
    "\n",
    "3. **Iteration:** In each iteration k+1, new values of x are calculated based on values from the previous iteration k:\n",
    "    ```\n",
    "    x⁽ᵏ⁺¹⁾ᵢ = (bᵢ - Σⱼ₌₁,ⱼ≠ᵢ aᵢⱼx⁽ᵏ⁾ⱼ) / aᵢᵢ\n",
    "    ```\n",
    "\n",
    "4. **Convergence:** The method is convergent when:\n",
    "    - Matrix A is diagonally dominant\n",
    "    - Elements on the main diagonal are non-zero\n",
    "\n",
    "5. **Stopping criterion:** Iterations are performed until a specified accuracy ε is reached:\n",
    "    ```\n",
    "    ||x⁽ᵏ⁺¹⁾ - x⁽ᵏ⁾|| < ε\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d2d2df",
   "metadata": {},
   "source": [
    "## Gauss-Seidel Iterative Method\n",
    "\n",
    "The Gauss-Seidel method is an improved version of the Jacobi method, in which updated values from the current iteration are immediately used to calculate new x values.\n",
    "\n",
    "1. **Initial condition:** System of equations in the form Ax = b.\n",
    "\n",
    "2. **System transformation:** Similar to the Jacobi method, each unknown is expressed through the remaining variables.\n",
    "\n",
    "3. **Iteration:** New x values are calculated sequentially, immediately using the most recent available values:\n",
    "    ```\n",
    "    x⁽ᵏ⁺¹⁾ᵢ = (bᵢ - Σⱼ₌₁ⁱ₋₁ aᵢⱼx⁽ᵏ⁺¹⁾ⱼ - Σⱼ₌ᵢ₊₁ⁿ aᵢⱼx⁽ᵏ⁾ⱼ) / aᵢᵢ\n",
    "    ```\n",
    "\n",
    "4. **Convergence:** The Gauss-Seidel method is convergent when matrix A is diagonally dominant or positive definite.  \n",
    "    - **Diagonally dominant matrix:** For each row i:\n",
    "      $$\n",
    "      |a_{ii}| > \\sum_{j \\neq i} |a_{ij}|\n",
    "      $$\n",
    "    - **Positive definite matrix:** For every non-zero vector $x$: $x^T A x > 0$.  \n",
    "    Satisfying one of these conditions guarantees convergence of the method.\n",
    "\n",
    "5. **Stopping criterion:** Iterations are performed until a specified accuracy ε is reached:\n",
    "    ```\n",
    "    ||x⁽ᵏ⁺¹⁾ - x⁽ᵏ⁾|| < ε\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a74d91",
   "metadata": {},
   "source": [
    "## SOR (Successive Over-Relaxation) Iterative Method\n",
    "\n",
    "The SOR method is an extension of the Gauss-Seidel method, which introduces a relaxation parameter ω (omega) to accelerate convergence.\n",
    "\n",
    "1. **Initial condition:** System of equations in the form Ax = b.\n",
    "\n",
    "2. **System transformation:** Each unknown is expressed through the remaining variables, as in previous methods.\n",
    "\n",
    "3. **Iteration:** New x values are calculated using the relaxation parameter ω:\n",
    "    ```\n",
    "    x⁽ᵏ⁺¹⁾ᵢ = (1 - ω)x⁽ᵏ⁾ᵢ + (ω / aᵢᵢ) * (bᵢ - Σⱼ₌₁ⁱ₋₁ aᵢⱼx⁽ᵏ⁺¹⁾ⱼ - Σⱼ₌ᵢ₊₁ⁿ aᵢⱼx⁽ᵏ⁾ⱼ)\n",
    "    ```\n",
    "    where 0 < ω < 2.\n",
    "\n",
    "4. **Convergence:**  \n",
    "    - The SOR method is convergent when matrix A is **positive definite** or **strictly diagonally dominant**.  \n",
    "    - In practice, for diagonally dominant or positive definite matrices, there exists a value of the relaxation parameter ω (usually $1 < \\omega < 2$), for which the SOR method converges faster than Gauss-Seidel.  \n",
    "    - The choice of optimal ω depends on the properties of the matrix - too small or too large values can slow down convergence or even make it impossible.  \n",
    "    - **Formal conditions:**  \n",
    "      - If A is a symmetric and positive definite matrix, the SOR method is convergent for $0 < \\omega < 2$.  \n",
    "      - If A is strictly diagonally dominant, the SOR method is also convergent for $0 < \\omega < 2$.  \n",
    "    - For matrices that do not satisfy these conditions, the SOR method may not be convergent regardless of the choice of ω.\n",
    "\n",
    "5. **Stopping criterion:** Iterations are performed until a specified accuracy ε is reached:\n",
    "    ```\n",
    "    ||x⁽ᵏ⁺¹⁾ - x⁽ᵏ⁾|| < ε\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from functools import wraps\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
    "\n",
    "timings = {'jacobi': [], 'gauss_seidel': [], 'sor': []}\n",
    "iterations = {'jacobi': [], 'gauss_seidel': [], 'sor': []}\n",
    "sizes = []\n",
    "\n",
    "def record_stats(method_name, size, elapsed, iters):\n",
    "    timings[method_name].append(elapsed)\n",
    "    iterations[method_name].append(iters)\n",
    "    if method_name == 'jacobi':\n",
    "        sizes.append(size)\n",
    "\n",
    "def timer(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result, iter_count, printExtended = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        method_name = func.__name__\n",
    "        A = args[0]\n",
    "        size = A.shape[0]\n",
    "        record_stats(method_name, size, elapsed, iter_count)\n",
    "        if printExtended:\n",
    "            print(f\"{method_name} took {elapsed:.4f} seconds to execute\")\n",
    "            print(f\"{method_name} solution: {result}\")\n",
    "            print(f\"Number of iterations: {iter_count}\\n\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def jacobi(A, b, x0=None, tol=1e-10, max_iter=1000, printExtended=True):\n",
    "    n = len(b)\n",
    "    x = np.zeros_like(b) if x0 is None else x0.copy()\n",
    "    D = np.diag(A)\n",
    "    if np.any(np.abs(D) < 1e-10):\n",
    "        raise ValueError(\"Matrix contains zeros on the diagonal\")\n",
    "        \n",
    "    R = A - np.diagflat(D)\n",
    "    iter_count = 0\n",
    "    \n",
    "    while iter_count < max_iter:\n",
    "        x_new = (b - np.dot(R, x)) / D\n",
    "        if np.linalg.norm(x_new - x, ord=np.inf) < tol:\n",
    "            return x_new, iter_count, printExtended\n",
    "        x = x_new\n",
    "        iter_count += 1\n",
    "        \n",
    "    raise ValueError(f\"Failed to converge after {max_iter} iterations\")\n",
    "\n",
    "@timer\n",
    "def gauss_seidel(A, b, x0=None, tol=1e-10, max_iter=1000, printExtended=True):\n",
    "    n = len(b)\n",
    "    x = np.zeros_like(b) if x0 is None else x0.copy()\n",
    "    iter_count = 0\n",
    "    if np.any(np.abs(np.diag(A)) < 1e-10):\n",
    "        raise ValueError(\"Matrix contains zeros on the diagonal\")\n",
    "    \n",
    "    while iter_count < max_iter:\n",
    "        x_new = x.copy()\n",
    "        for i in range(n):\n",
    "            sum1 = np.dot(A[i, :i], x_new[:i])\n",
    "            sum2 = np.dot(A[i, i+1:], x[i+1:])\n",
    "            x_new[i] = (b[i] - sum1 - sum2) / A[i, i]\n",
    "        if np.linalg.norm(x_new - x, ord=np.inf) < tol:\n",
    "            return x_new, iter_count, printExtended\n",
    "        x = x_new\n",
    "        iter_count += 1\n",
    "        \n",
    "    raise ValueError(f\"Failed to converge after {max_iter} iterations\")\n",
    "\n",
    "@timer\n",
    "def sor(A, b, x0=None, omega=1.0, tol=1e-10, max_iter=1000, printExtended=True):\n",
    "    n = len(b)\n",
    "    x = np.zeros_like(b) if x0 is None else x0.copy()\n",
    "    iter_count = 0\n",
    "    if np.any(np.abs(np.diag(A)) < 1e-10):\n",
    "        raise ValueError(\"Matrix contains zeros on the diagonal\")\n",
    "    \n",
    "    while iter_count < max_iter:\n",
    "        x_new = x.copy()\n",
    "        for i in range(n):\n",
    "            sum1 = np.dot(A[i, :i], x_new[:i])\n",
    "            sum2 = np.dot(A[i, i+1:], x[i+1:])\n",
    "            x_new[i] = (1 - omega) * x[i] + (omega * (b[i] - sum1 - sum2)) / A[i, i]\n",
    "        if np.linalg.norm(x_new - x, ord=np.inf) < tol:\n",
    "            return x_new, iter_count, printExtended\n",
    "        x = x_new\n",
    "        iter_count += 1\n",
    "        \n",
    "    raise ValueError(f\"Failed to converge after {max_iter} iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec07d0",
   "metadata": {},
   "source": [
    "---\n",
    "## Test on the example from the presentation\n",
    "Comparison of results, execution times, and the number of required iterations for all three methods using the example given in the presentation:\n",
    "\n",
    "**Matrix A:**\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "3 & -1 & 0 & 0 & 0 & -1 \\\\\n",
    "-1 & 3 & -1 & 0 & -1 & 0 \\\\\n",
    "0 & -1 & 3 & -1 & 0 & 0 \\\\\n",
    "0 & 0 & -1 & 3 & -1 & 0 \\\\\n",
    "0 & -1 & 0 & -1 & 3 & -1 \\\\\n",
    "-1 & 0 & 0 & 0 & -1 & 3 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Vector b:**\n",
    "$$\n",
    "b = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "20 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Below are the results, execution times, and number of iterations for Jacobi, Gauss-Seidel, and SOR methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3,-1,0,0,0,-1], \n",
    "                  [-1,3,-1,0,-1,0],\n",
    "                  [0,-1,3,-1,0,0],\n",
    "                  [0,0,-1,3,-1,0],\n",
    "                  [0,-1,0,-1,3,-1],\n",
    "                  [-1,0,0,0,-1,3]], dtype=float)\n",
    "b = np.array([0, 0, 0, 0, 0, 20], dtype=float)\n",
    "print(\"Solving Ax = b using Jacobi, Gauss-Seidel, and SOR methods:\\n\")\n",
    "print(f\"Matrix A: {A}\")\n",
    "print(f\"Vector b: {b}\\n\")\n",
    "jacobi(A, b)\n",
    "gauss_seidel(A, b)\n",
    "sor(A, b, omega=1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d7a37f",
   "metadata": {},
   "source": [
    "## Results Comparison \n",
    "  \n",
    "For the example 6x6 matrix, all three methods (Jacobi, Gauss-Seidel, SOR) give very similar results, and the number of iterations and execution time are small:\n",
    "\n",
    "- **Jacobi:** 111 iterations, time ≈ 0.0033 s  \n",
    "- **Gauss-Seidel:** 59 iterations, time ≈ 0.0039 s  \n",
    "- **SOR (ω=1.25):** 31 iterations, time ≈ 0.0011 s  \n",
    "\n",
    "It is evident that the SOR method is the fastest and requires the fewest iterations, which confirms its advantage when the relaxation parameter is appropriately chosen.  \n",
    "The Gauss-Seidel method is significantly faster than Jacobi, but slower than SOR.  \n",
    "For small matrices, the differences are small, but with larger sizes, the advantage of SOR and Gauss-Seidel becomes more apparent.\n",
    "## Test for larger matrix\n",
    "We will compare results for an example matrix of size 100x100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe04f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_big = 100\n",
    "A_big = np.random.rand(n_big, n_big)\n",
    "for i in range(n_big):\n",
    "    A_big[i, i] = np.sum(np.abs(A_big[i])) + 1\n",
    "b_big = np.random.rand(n_big)\n",
    "print(\"Solving large Ax = b using Jacobi, Gauss-Seidel, and SOR methods:\\n\")\n",
    "print(f\"Matrix A_big shape: {A_big.shape}\")\n",
    "print(f\"Vector b_big shape: {b_big.shape}\\n\")\n",
    "jacobi(A_big, b_big)\n",
    "gauss_seidel(A_big, b_big)\n",
    "sor(A_big, b_big, omega=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2e8162",
   "metadata": {},
   "source": [
    "## Results Comparison\n",
    "  \n",
    "For the 100x100 matrix, the differences between methods become more noticeable:\n",
    "\n",
    "- **Jacobi:** 616 iterations, time ≈ 0.0112 s  \n",
    "- **Gauss-Seidel:** 14 iterations, time ≈ 0.0079 s  \n",
    "- **SOR (ω=1.1):** 17 iterations, time ≈ 0.0139 s  \n",
    "\n",
    "For larger matrices, the Gauss-Seidel and SOR methods show much better convergence than the Jacobi method. The number of Jacobi iterations grows very quickly, while Gauss-Seidel and SOR achieve a solution in just a few steps. The execution time for all methods remains low, but the advantage of the Gauss-Seidel and SOR methods is clear in terms of iteration count, although a single iteration of these solutions takes noticeably longer than with the Jacobi method.  \n",
    "In the next steps, a comparison for even larger matrices and a larger number of them will be conducted, and based on this, a graph of the number of iterations versus matrix size and solution time versus matrix size will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_big in range(200, 2001, 100):\n",
    "    np.random.seed(42)\n",
    "    A_big = np.random.rand(n_big, n_big)\n",
    "    for i in range(n_big):\n",
    "        A_big[i, i] = np.sum(np.abs(A_big[i])) + 1\n",
    "    b_big = np.random.rand(n_big)\n",
    "    jacobi(A_big, b_big, printExtended=False, max_iter=float(\"inf\"))\n",
    "    gauss_seidel(A_big, b_big, printExtended=False)\n",
    "    sor(A_big, b_big, omega=1.1, printExtended=False)\n",
    "\n",
    "for n_big in range(2200, 4001, 200):\n",
    "    np.random.seed(42)\n",
    "    A_big = np.random.rand(n_big, n_big)\n",
    "    for i in range(n_big):\n",
    "        A_big[i, i] = np.sum(np.abs(A_big[i])) + 1\n",
    "    b_big = np.random.rand(n_big)\n",
    "    jacobi(A_big, b_big, printExtended=False, max_iter=float(\"inf\"))\n",
    "    gauss_seidel(A_big, b_big, printExtended=False)\n",
    "    sor(A_big, b_big, omega=1.1, printExtended=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot timings\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for method in timings:\n",
    "    plt.plot(sizes, timings[method], marker='o', label=method.capitalize())\n",
    "plt.xlabel('Matrix size (n)')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Execution Time vs Matrix Size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot iterations\n",
    "plt.subplot(1, 2, 2)\n",
    "for method in iterations:\n",
    "    plt.plot(sizes, iterations[method], marker='o', label=method.capitalize())\n",
    "plt.xlabel('Matrix size (n)')\n",
    "plt.ylabel('Number of Iterations')\n",
    "plt.title('Iterations vs Matrix Size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ebdeb",
   "metadata": {},
   "source": [
    "## Graph Analysis\n",
    "With larger matrices, the difference in both execution time and the number of iterations needed becomes very clear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b0630",
   "metadata": {},
   "source": [
    "## Examples of matrices for which these methods don't converge\n",
    "Examples of matrices for which iterative methods don't converge:\n",
    "\n",
    "**1. Matrices with zeros on the diagonal**  \n",
    "Any matrix with zeros on the diagonal immediately causes problems:  \n",
    "Example:  \n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "0 & 1 & 2 \\\\\n",
    "1 & 2 & 0 \\\\\n",
    "3 & 0 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**2. Matrices that are not positive definite**  \n",
    "When a symmetric matrix is not positive definite:  \n",
    "Example:  \n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "2 & -1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e941b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "# Set time limit in seconds\n",
    "TIMEOUT = 5\n",
    "\n",
    "def run_with_timeout(func, *args, timeout=TIMEOUT, **kwargs):\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        future = executor.submit(func, *args, **kwargs)\n",
    "        try:\n",
    "            return future.result(timeout=timeout)\n",
    "        except TimeoutError:\n",
    "            raise TimeoutException(\"Time limit exceeded\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "print(\"Running tests on problematic matrices...\\n\")\n",
    "\n",
    "# 1. Matrix with zeros on the diagonal\n",
    "print(\"Test 1: Matrix with zeros on the diagonal\")\n",
    "A_zero_diag = np.array([\n",
    "    [0, 1, 2],\n",
    "    [1, 2, 0],\n",
    "    [3, 0, 0]\n",
    "], dtype=float)\n",
    "b_zero_diag = np.array([1, 2, 3], dtype=float)\n",
    "\n",
    "for method_func, name, kwargs in [\n",
    "    (jacobi, \"Jacobi\", {\"max_iter\": 100}),\n",
    "    (gauss_seidel, \"Gauss-Seidel\", {\"max_iter\": 100}),\n",
    "    (sor, \"SOR\", {\"omega\": 1.1, \"max_iter\": 100})\n",
    "]:\n",
    "    try:\n",
    "        result = run_with_timeout(method_func, A_zero_diag, b_zero_diag, printExtended=False, **kwargs)\n",
    "        print(f\"{name}: Unexpectedly convergent (should fail with zeros on the diagonal)\")\n",
    "    except TimeoutException as e:\n",
    "        print(f\"{name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name}: {str(e)}\")\n",
    "print()\n",
    "\n",
    "# 2. Non-positive definite matrix\n",
    "print(\"Test 2: Non-positive definite matrix\")\n",
    "A_not_posdef = np.array([\n",
    "    [1, 2],\n",
    "    [2, -1]\n",
    "], dtype=float)\n",
    "b_not_posdef = np.array([1, 1], dtype=float)\n",
    "\n",
    "for method_func, name, kwargs in [\n",
    "    (jacobi, \"Jacobi\", {\"max_iter\": 500}),\n",
    "    (gauss_seidel, \"Gauss-Seidel\", {\"max_iter\": 500}),\n",
    "    (sor, \"SOR\", {\"omega\": 1.1, \"max_iter\": 500})\n",
    "]:\n",
    "    try:\n",
    "        result = run_with_timeout(method_func, A_not_posdef, b_not_posdef, printExtended=False, **kwargs)\n",
    "        print(f\"{name}: Convergent to {result}\")\n",
    "    except TimeoutException as e:\n",
    "        print(f\"{name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name}: {str(e)}\")\n",
    "print()\n",
    "\n",
    "# 3. Non-diagonally dominant matrix\n",
    "print(\"Test 3: Non-diagonally dominant matrix\")\n",
    "A_not_diag_dom = np.array([\n",
    "    [1, 2],\n",
    "    [3, 1]\n",
    "], dtype=float)\n",
    "b_not_diag_dom = np.array([5, 6], dtype=float)\n",
    "\n",
    "for method_func, name, kwargs in [\n",
    "    (jacobi, \"Jacobi\", {\"max_iter\": 500}),\n",
    "    (gauss_seidel, \"Gauss-Seidel\", {\"max_iter\": 500}),\n",
    "    (sor, \"SOR\", {\"omega\": 0.5, \"max_iter\": 500})\n",
    "]:\n",
    "    try:\n",
    "        result = run_with_timeout(method_func, A_not_diag_dom, b_not_diag_dom, printExtended=False, **kwargs)\n",
    "        print(f\"{name}: Convergent to {result}\")\n",
    "    except TimeoutException as e:\n",
    "        print(f\"{name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name}: {str(e)}\")\n",
    "print()\n",
    "\n",
    "# 4. Ill-conditioned matrix\n",
    "print(\"Test 4: Ill-conditioned matrix\")\n",
    "A_ill_cond = np.array([\n",
    "    [1000, 999],\n",
    "    [999, 998]\n",
    "], dtype=float)\n",
    "b_ill_cond = np.array([1999, 1997], dtype=float)\n",
    "\n",
    "for method_func, name, kwargs in [\n",
    "    (jacobi, \"Jacobi\", {\"max_iter\": 5000}),\n",
    "    (gauss_seidel, \"Gauss-Seidel\", {\"max_iter\": 5000}),\n",
    "    (sor, \"SOR\", {\"omega\": 0.8, \"max_iter\": 5000})\n",
    "]:\n",
    "    try:\n",
    "        result = run_with_timeout(method_func, A_ill_cond, b_ill_cond, printExtended=False, **kwargs)\n",
    "        print(f\"{name}: Convergent to {result}\")\n",
    "    except TimeoutException as e:\n",
    "        print(f\"{name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name}: {str(e)}\")\n",
    "print()\n",
    "\n",
    "# 5. Matrix with complex eigenvalues\n",
    "print(\"Test 5: Matrix with complex eigenvalues outside the unit circle\")\n",
    "A_complex = np.array([\n",
    "    [3, 4],\n",
    "    [-4, 3]\n",
    "], dtype=float)\n",
    "b_complex = np.array([7, -1], dtype=float)\n",
    "\n",
    "for method_func, name, kwargs in [\n",
    "    (jacobi, \"Jacobi\", {\"max_iter\": 1000}),\n",
    "    (gauss_seidel, \"Gauss-Seidel\", {\"max_iter\": 1000}),\n",
    "    (sor, \"SOR\", {\"omega\": 0.5, \"max_iter\": 1000})\n",
    "]:\n",
    "    try:\n",
    "        result = run_with_timeout(method_func, A_complex, b_complex, printExtended=False, **kwargs)\n",
    "        print(f\"{name}: Convergent to {result}\")\n",
    "    except TimeoutException as e:\n",
    "        print(f\"{name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name}: {str(e)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f7efb9",
   "metadata": {},
   "source": [
    "---\n",
    "## Graph of convergence rate for given error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0986dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of convergence speed depending on specified error (tolerance)\n",
    "tolerances = [float(\"1e-\" + str(x)) for x in range(30)]\n",
    "jacobi_iters_tol, gs_iters_tol, sor_iters_tol = [], [], []\n",
    "jacobi_times_tol, gs_times_tol, sor_times_tol = [], [], []\n",
    "\n",
    "n_test = 100\n",
    "A_test = np.random.rand(n_test, n_test)\n",
    "for i in range(n_test):\n",
    "    A_test[i, i] = np.sum(np.abs(A_test[i])) + 1\n",
    "b_test = np.random.rand(n_test)\n",
    "\n",
    "\n",
    "for tol in tolerances:\n",
    "    # Jacobi\n",
    "    start = time.time()\n",
    "    try:\n",
    "        _, iters, _ = jacobi.__wrapped__(A_test, b_test, tol=tol, printExtended=False)\n",
    "        jacobi_iters_tol.append(iters)\n",
    "        jacobi_times_tol.append(time.time() - start)\n",
    "    except Exception:\n",
    "        jacobi_iters_tol.append(np.nan)\n",
    "        jacobi_times_tol.append(np.nan)\n",
    "    # Gauss-Seidel\n",
    "    start = time.time()\n",
    "    try:\n",
    "        _, iters, _ = gauss_seidel.__wrapped__(A_test, b_test, tol=tol, printExtended=False)\n",
    "        gs_iters_tol.append(iters)\n",
    "        gs_times_tol.append(time.time() - start)\n",
    "    except Exception:\n",
    "        gs_iters_tol.append(np.nan)\n",
    "        gs_times_tol.append(np.nan)\n",
    "    # SOR (omega=1.1)\n",
    "    start = time.time()\n",
    "    try:\n",
    "        _, iters, _ = sor.__wrapped__(A_test, b_test, omega=1.1, tol=tol, printExtended=False)\n",
    "        sor_iters_tol.append(iters)\n",
    "        sor_times_tol.append(time.time() - start)\n",
    "    except Exception:\n",
    "        sor_iters_tol.append(np.nan)\n",
    "        sor_times_tol.append(np.nan)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(tolerances, jacobi_iters_tol, marker='o', label='Jacobi')\n",
    "plt.plot(tolerances, gs_iters_tol, marker='o', label='Gauss-Seidel')\n",
    "plt.plot(tolerances, sor_iters_tol, marker='o', label='SOR (ω=1.1)')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Tolerance (error)')\n",
    "plt.ylabel('Number of iterations')\n",
    "plt.title('Number of iterations vs tolerance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(tolerances, jacobi_times_tol, marker='o', label='Jacobi')\n",
    "plt.plot(tolerances, gs_times_tol, marker='o', label='Gauss-Seidel')\n",
    "plt.plot(tolerances, sor_times_tol, marker='o', label='SOR (ω=1.1)')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Tolerance (error)')\n",
    "plt.ylabel('Execution time (s)')\n",
    "plt.title('Execution time vs tolerance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f673d",
   "metadata": {},
   "source": [
    "---\n",
    "## Graph of the effect of relaxation parameter on SOR method convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524293eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "omegas = np.arange(0.1, 2.0, 0.05)\n",
    "sor_iters = []\n",
    "sor_times = []\n",
    "\n",
    "# We'll use A_big and b_big from previous tests\n",
    "n_test = 100\n",
    "np.random.seed(42)\n",
    "A_test = np.random.rand(n_test, n_test)\n",
    "for i in range(n_test):\n",
    "    A_test[i, i] = np.sum(np.abs(A_test[i])) + 1\n",
    "b_test = np.random.rand(n_test)\n",
    "\n",
    "for omega in omegas:\n",
    "    try:\n",
    "        start = time.time()\n",
    "        _, iters, _ = sor.__wrapped__(A_test, b_test, omega=omega, printExtended=False)\n",
    "        elapsed = time.time() - start\n",
    "        sor_iters.append(iters)\n",
    "        sor_times.append(elapsed)\n",
    "    except Exception:\n",
    "        sor_iters.append(np.nan)\n",
    "        sor_times.append(np.nan)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(omegas, sor_iters, marker='o')\n",
    "plt.xlabel('Relaxation parameter ω')\n",
    "plt.ylabel('Number of iterations to convergence')\n",
    "plt.title('Effect of ω on number of SOR iterations')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(omegas, sor_times, marker='o', color='orange')\n",
    "plt.xlabel('Relaxation parameter ω')\n",
    "plt.ylabel('Execution time (s)')\n",
    "plt.title('Effect of ω on SOR execution time')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
